<!-- This is an HTML page for the JNL221 class' first repository.-->

<!DOCTYPE html>
<html>
	<head>
	
		<meta charset="utf-8">
		<title>First repository</title>
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,400,300,600,700&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
		<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
	
		<!-- This is where this page's style sheet is defined. -->
		<link type="text/css" rel="stylesheet" href="index.css" />

	</head>
	<body>
	
		<!-- This is the header row for this page. -->
		<div id="intro">
			<h1>Vivian Collins</h1>
			<h4>Syracuse University, Fall 2025</h4>
		</div>

		<section>
			<p>I was surprised by all the different examples of AI being misused or used in a way that negatively impacts people that I hadn’t heard about. The documentary came out in 2020 and featured several stories about AI that I feel did not enter the mainstream news cycle. Or I was too young or ignorant to be paying attention to them. I did not know that AI was being used in courts to help with sentencing, specifically in Pennsylvania, the state where I’m from. I found this alarming as the documentary admitted AI carries bias and uses race and gender to determine if someone is likely to commit or have committed a crime. I think using an AI model like this is dangerous to the justice system and creates more room for false sentences. 
				</p>
				<p>I have always been a fan of science fiction movies and watched all the movies featured at the beginning of the documentary. In those movies and other aspects of pop culture, AI is usually depicted one of two ways. The first one is the supportive, smart character or entity that’s designed to help humans, like Jarvis from the Marvel Cinematic Universe. The second is the world-ending army of AI androids that are determined to end the human race because they “know better.” The documentary focused more on how AI regularly impacts people in ways we don’t always see. Instead of the AI taking over the world like in movies, the AI model in the documentary that sorted through resumes eliminated applicants if they were a woman or mentioned women. I also found the mention of “Tay” to be interesting because it showed how humans can influence AI and how the model immediately became hateful and bigoted. Additionally, the AI in the documentary emphasized “powerful people scoring powerless people.” This statement does an excellent job of describing the inequality AI is perpetuating.<p>
					<p>This dataset shows examples of AI incidents, several of which involve people dying or getting seriously injured. If I were to “interview” the dataset to find a story, I’d be curious about who is behind these incidents. I would first ask the dataset, “What are the most common organizations/companies that are responsible for the AI models or algorithms causing the incidents?” The second question I would ask would be about the aftermath of the incident: “What was done after the incident to solve the problem moving forward? Were amends made? How can you ensure this won’t happen again?” My hypothesis is: AI models and algorithms do not undergo enough testing and quality assurance before becoming available to the general public.<p> 
		</section>

		<div id="end">
			<h4>this page was published on github pages. fonts: montserrat, open sans.</h4>
		</div>


	</body>
</html>